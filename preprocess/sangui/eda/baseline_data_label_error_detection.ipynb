{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZFRz66WGJ0m"
   },
   "source": [
    "# Data-Centric NLP 대회: 주제 분류 프로젝트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ-n74gNGJ0n"
   },
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2336,
     "status": "ok",
     "timestamp": 1730638499594,
     "user": {
      "displayName": "Ster Te",
      "userId": "04580952454318408657"
     },
     "user_tz": -540
    },
    "id": "xV7_BUXLRXu8",
    "outputId": "21e54385-3d05-4e00-bf64-4f2d394192dd"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    %cd /content/drive/MyDrive/newstopic/code\n",
    "    !pip install -r requirements.txt\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5444,
     "status": "ok",
     "timestamp": 1730638505035,
     "user": {
      "displayName": "Ster Te",
      "userId": "04580952454318408657"
     },
     "user_tz": -540
    },
    "id": "o8WQMjfdRUNL",
    "outputId": "89725dc7-588b-487e-a0fc-65cb208651d2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 16981,
     "status": "ok",
     "timestamp": 1730638522013,
     "user": {
      "displayName": "Ster Te",
      "userId": "04580952454318408657"
     },
     "user_tz": -540
    },
    "id": "ieJqZz6WGJ0n"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import evaluate\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9MrGeVLGJ0o"
   },
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730638522014,
     "user": {
      "displayName": "Ster Te",
      "userId": "04580952454318408657"
     },
     "user_tz": -540
    },
    "id": "Rojb26TRGJ0o"
   },
   "outputs": [],
   "source": [
    "SEED = 456\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730638522014,
     "user": {
      "displayName": "Ster Te",
      "userId": "04580952454318408657"
     },
     "user_tz": -540
    },
    "id": "NHiKw7tAGJ0o",
    "outputId": "df3eb193-23c3-4419-c7e0-f92c99e9f05d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730638522014,
     "user": {
      "displayName": "Ster Te",
      "userId": "04580952454318408657"
     },
     "user_tz": -540
    },
    "id": "ANUH4JCxGJ0o"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, '../data')\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, '../output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuP9IW9mGJ0o"
   },
   "source": [
    "## Load Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3180,
     "status": "ok",
     "timestamp": 1730638525191,
     "user": {
      "displayName": "Ster Te",
      "userId": "04580952454318408657"
     },
     "user_tz": -540
    },
    "id": "HH0lhDvhGJ0o",
    "outputId": "fa6bddce-b0e7-473c-e428-ed7099bd22fb"
   },
   "outputs": [],
   "source": [
    "model_name = '../model/rlm/checkpoint-200'\n",
    "tokenizer_name = 'klue/bert-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=7).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-x2NvoGbGJ0o"
   },
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1730638528420,
     "user": {
      "displayName": "Ster Te",
      "userId": "04580952454318408657"
     },
     "user_tz": -540
    },
    "id": "9BQVS286GJ0o"
   },
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        input_texts = data['text']\n",
    "        targets = data['target']\n",
    "        self.inputs = []; self.labels = []\n",
    "        for text, label in zip(input_texts, targets):\n",
    "            tokenized_input = tokenizer(text, padding='max_length', truncation=True, return_tensors='pt')\n",
    "            self.inputs.append(tokenized_input)\n",
    "            self.labels.append(torch.tensor(label))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.inputs[idx]['input_ids'].squeeze(0),\n",
    "            'attention_mask': self.inputs[idx]['attention_mask'].squeeze(0),\n",
    "            'labels': self.labels[idx].squeeze(0)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBERTDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        input_texts = data['text']\n",
    "        targets = data['target']\n",
    "        self.inputs = []; self.labels = []\n",
    "        for text, label in zip(input_texts, targets):\n",
    "            tokenized_input = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "            self.inputs.append(tokenized_input)\n",
    "            self.labels.append(torch.tensor(label).view(1,-1))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.inputs[idx]['input_ids'],\n",
    "            'attention_mask': self.inputs[idx]['attention_mask'],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1730638533013,
     "user": {
      "displayName": "Ster Te",
      "userId": "04580952454318408657"
     },
     "user_tz": -540
    },
    "id": "5yh5dYa0GJ0p"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPl6TZ7CGJ0p"
   },
   "source": [
    "## Define Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1730638533699,
     "user": {
      "displayName": "Ster Te",
      "userId": "04580952454318408657"
     },
     "user_tz": -540
    },
    "id": "XA9g2vV_GJ0p"
   },
   "outputs": [],
   "source": [
    "f1 = evaluate.load('f1')\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return f1.compute(predictions=predictions, references=labels, average='macro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WV2exsooGJ0p"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1730638533701,
     "user": {
      "displayName": "Ster Te",
      "userId": "04580952454318408657"
     },
     "user_tz": -540
    },
    "id": "OkQVpzabGJ0p"
   },
   "outputs": [],
   "source": [
    "## for wandb setting\n",
    "os.environ['WANDB_DISABLED'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class CleanlabModel(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model, optimizer, criterion):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.epochs = 2\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "\n",
    "        self.model.train()\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for x in X:\n",
    "                x['input_ids'] = x['input_ids'].to(self.device)\n",
    "                x['attention_mask'] = x['attention_mask'].to(self.device)\n",
    "                y = x['labels'].to(self.device)\n",
    "                del x['labels']\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(**x)\n",
    "                loss = self.criterion(outputs.logits, y.view(1))\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        probs_list = []\n",
    "        with torch.no_grad():\n",
    "            for x in X:\n",
    "                x['input_ids'] = x['input_ids'].to(self.device)\n",
    "                x['attention_mask'] = x['attention_mask'].to(self.device)\n",
    "                del x['labels']\n",
    "                outputs = self.model(**x)\n",
    "                probs = F.softmax(outputs.logits, dim=-1).detach().cpu().numpy()\n",
    "                probs_list += [probs]\n",
    "        probs = np.concatenate(probs_list, axis=0)\n",
    "        return probs\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return probs.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBXeP6ynGJ0p"
   },
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cleanlab filter\n",
    "from cleanlab.filter import find_label_issues\n",
    "from cleanlab.classification import CleanLearning\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def label_print(model, file_name):\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    data_train = pd.read_csv(file_name)\n",
    "    dataset_train = BERTDataset(data_train, tokenizer)\n",
    "\n",
    "    train_pred_probs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataset_train:\n",
    "            #batch['input_ids'] = batch['input_ids']\n",
    "            batch['input_ids'] = batch['input_ids'].view(1, -1).to(DEVICE)\n",
    "            batch['attention_mask'] = batch['attention_mask'].view(1, -1).to(DEVICE)\n",
    "            batch['labels'] = batch['labels'].view(1, -1).to(DEVICE)\n",
    "            outputs = model(**batch)\n",
    "            train_pred_probs += [torch.nn.functional.softmax(outputs.logits, dim=-1)]\n",
    "\n",
    "    train_pred_probs = torch.cat(train_pred_probs, dim=0)\n",
    "    train_pred_probs = train_pred_probs.detach().cpu().numpy()\n",
    "    ordered_label_issues = find_label_issues(\n",
    "        labels=data_train['target'],\n",
    "        pred_probs=train_pred_probs,\n",
    "        return_indices_ranked_by='self_confidence',\n",
    "    )\n",
    "\n",
    "    head_issues = ordered_label_issues[:3]\n",
    "    for issue in head_issues:\n",
    "        print('input_text:', data_train.iloc[issue]['text'])\n",
    "        print('label_text:', data_train.iloc[issue]['target'])\n",
    "        print('-------------------------------------------------')\n",
    "\n",
    "    from cleanlab.dataset import health_summary\n",
    "    class_names = [*range(7)]\n",
    "    health_summary(data_train['target'], train_pred_probs, class_names=class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel(model, file_name):\n",
    "    data_train = pd.read_csv(file_name)\n",
    "    dataset_train = BERTDataset(data_train, tokenizer)\n",
    "\n",
    "    train_pred_probs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataset_train:\n",
    "            #batch['input_ids'] = batch['input_ids']\n",
    "            batch['input_ids'] = batch['input_ids'].view(1, -1).to(DEVICE)\n",
    "            batch['attention_mask'] = batch['attention_mask'].view(1, -1).to(DEVICE)\n",
    "            batch['labels'] = batch['labels'].view(1, -1).to(DEVICE)\n",
    "            outputs = model(**batch)\n",
    "            train_pred_probs += [torch.nn.functional.softmax(outputs.logits, dim=-1)]\n",
    "\n",
    "    train_pred_probs = torch.cat(train_pred_probs, dim=0)\n",
    "    train_pred_probs = train_pred_probs.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    print(\"relabeling start\")\n",
    "    model = CleanlabModel(model, torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01), torch.nn.CrossEntropyLoss())\n",
    "    cleanlab_relabel = CleanLearning(clf=model, seed=SEED)  # You can pass your PyTorch model\n",
    "    cleanlab_relabel.fit(MyBERTDataset(data_train, tokenizer), data_train['target'], pred_probs=train_pred_probs)  # You can pass the dataset and predicted probabilities\n",
    "\n",
    "    new_labels = cleanlab_relabel.predict(MyBERTDataset(data_train, tokenizer))  # Get the new labels for relabeling\n",
    "    print(\"new_labels\", new_labels)\n",
    "    return cleanlab_relabel, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cleanlab filter\n",
    "from cleanlab.filter import find_label_issues\n",
    "\n",
    "label_print(model, '../data/preprocess/ascii_ratio_higher_20.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relabeling start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_labels [4 3 2 ... 1 1 4]\n"
     ]
    }
   ],
   "source": [
    "cleanlab_relabel, new_labels = relabel(model, '../data/preprocess/ascii_ratio_higher_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1639\n"
     ]
    }
   ],
   "source": [
    "print(len(new_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/preprocess/ascii_ratio_higher_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/preprocess/ascii_ratio_higher_20.csv')\n",
    "new_train_data = train_data.copy()\n",
    "new_train_data['target'] = new_labels\n",
    "\n",
    "train_data.to_csv('../data/preprocess/ascii_ratio_higher_20_not_relabeled.csv')\n",
    "new_train_data.to_csv('../data/preprocess/ascii_ratio_higher_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n"
     ]
    }
   ],
   "source": [
    "new_data = pd.read_csv('../data/preprocess/ascii_ratio_higher_20.csv')\n",
    "old_data = pd.read_csv('../data/preprocess/ascii_ratio_higher_20_not_relabeled.csv')\n",
    "c = 0\n",
    "for a ,b in zip(new_data.target, old_data.target):\n",
    "    if a!=b:c+=1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1730638537238,
     "user": {
      "displayName": "Ster Te",
      "userId": "04580952454318408657"
     },
     "user_tz": -540
    },
    "id": "SGcIcD7WK5AV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_text: 네이&3美 유11인;지Nj2회_A{문_2편j호평\n",
      "label_text: 4\n",
      "-------------------------------------------------\n",
      "input_text: =nb돌파' GO까…與3검`~혁H先처리1카드: r?~ 깬E\n",
      "label_text: 3\n",
      "-------------------------------------------------\n",
      "input_text: 메시·호날두 UEFA 올해의 팀에 선정…EPL 선수 제로\n",
      "label_text: 5\n",
      "-------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "|  Generating a Cleanlab Dataset Health Summary          |\n",
      "|   for your dataset with 1,153 examples and 7 classes.  |\n",
      "|  Note, Cleanlab is not a medical doctor... yet.        |\n",
      "----------------------------------------------------------\n",
      "\n",
      "Overall Class Quality and Noise across your dataset (below)\n",
      "------------------------------------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Label Issues</th>\n",
       "      <th>Inverse Label Issues</th>\n",
       "      <th>Label Noise</th>\n",
       "      <th>Inverse Label Noise</th>\n",
       "      <th>Label Quality Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>41</td>\n",
       "      <td>0.228916</td>\n",
       "      <td>0.242604</td>\n",
       "      <td>0.771084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>0.225166</td>\n",
       "      <td>0.120301</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>0.198758</td>\n",
       "      <td>0.227545</td>\n",
       "      <td>0.801242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>48</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.252632</td>\n",
       "      <td>0.835294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0.160920</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.839080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.079268</td>\n",
       "      <td>0.079268</td>\n",
       "      <td>0.920732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>0.065868</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.934132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Name  Class Index  Label Issues  Inverse Label Issues  Label Noise  \\\n",
       "0           3            3            38                    41     0.228916   \n",
       "1           6            6            34                    16     0.225166   \n",
       "2           5            5            32                    38     0.198758   \n",
       "3           4            4            28                    48     0.164706   \n",
       "4           0            0            28                    10     0.160920   \n",
       "5           2            2            13                    13     0.079268   \n",
       "6           1            1            11                    18     0.065868   \n",
       "\n",
       "   Inverse Label Noise  Label Quality Score  \n",
       "0             0.242604             0.771084  \n",
       "1             0.120301             0.774834  \n",
       "2             0.227545             0.801242  \n",
       "3             0.252632             0.835294  \n",
       "4             0.064103             0.839080  \n",
       "5             0.079268             0.920732  \n",
       "6             0.103448             0.934132  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Overlap. In some cases, you may want to merge classes in the top rows (below)\n",
      "-----------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Name A</th>\n",
       "      <th>Class Name B</th>\n",
       "      <th>Class Index A</th>\n",
       "      <th>Class Index B</th>\n",
       "      <th>Num Overlapping Examples</th>\n",
       "      <th>Joint Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>0.021683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.017346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0.016479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>0.014744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0.011275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.008673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.008673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.007806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.007806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.007806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.006071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class Name A  Class Name B  Class Index A  Class Index B  \\\n",
       "0              3             4              3              4   \n",
       "1              4             5              4              5   \n",
       "2              3             5              3              5   \n",
       "3              5             6              5              6   \n",
       "4              0             3              0              3   \n",
       "5              1             4              1              4   \n",
       "6              3             6              3              6   \n",
       "7              2             6              2              6   \n",
       "8              0             5              0              5   \n",
       "9              4             6              4              6   \n",
       "10             1             3              1              3   \n",
       "11             0             1              0              1   \n",
       "12             0             4              0              4   \n",
       "13             2             4              2              4   \n",
       "14             2             3              2              3   \n",
       "15             2             5              2              5   \n",
       "16             1             6              1              6   \n",
       "17             0             2              0              2   \n",
       "18             0             6              0              6   \n",
       "19             1             5              1              5   \n",
       "20             1             2              1              2   \n",
       "\n",
       "    Num Overlapping Examples  Joint Probability  \n",
       "0                         25           0.021683  \n",
       "1                         20           0.017346  \n",
       "2                         19           0.016479  \n",
       "3                         17           0.014744  \n",
       "4                         13           0.011275  \n",
       "5                         10           0.008673  \n",
       "6                         10           0.008673  \n",
       "7                          9           0.007806  \n",
       "8                          9           0.007806  \n",
       "9                          9           0.007806  \n",
       "10                         7           0.006071  \n",
       "11                         6           0.005204  \n",
       "12                         6           0.005204  \n",
       "13                         6           0.005204  \n",
       "14                         5           0.004337  \n",
       "15                         3           0.002602  \n",
       "16                         3           0.002602  \n",
       "17                         2           0.001735  \n",
       "18                         2           0.001735  \n",
       "19                         2           0.001735  \n",
       "20                         1           0.000867  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * Overall, about 11% (127 of the 1,153) labels in your dataset have potential issues.\n",
      " ** The overall label health score for this dataset is: 0.89.\n",
      "\n",
      "Generated with <3 from Cleanlab.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### cleanlab filter\n",
    "from cleanlab.filter import find_label_issues\n",
    "\n",
    "label_print(model, '../data/preprocess/ascii_ratio_higher_20_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_text: 메시 · 호날두 ·의FFA리그 올해의 축구 팀에 공식 선정 … 한국의의의 선수는 제로\n",
      "label_text: 5\n",
      "-------------------------------------------------\n",
      "input_text: 오늘은안당 안는는 안다 … 與 [UNK] 검 [UNK] [UNK] [UNK] [UNK] 先 처리 대통령 카드 안 안 안 안 안을 [UNK]다\n",
      "label_text: 3\n",
      "-------------------------------------------------\n",
      "input_text: 메리츠종금은 내년부터 코스피 ·에월월월 ∼월월월월의.\n",
      "label_text: 1\n",
      "-------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "|  Generating a Cleanlab Dataset Health Summary          |\n",
      "|   for your dataset with 1,153 examples and 7 classes.  |\n",
      "|  Note, Cleanlab is not a medical doctor... yet.        |\n",
      "----------------------------------------------------------\n",
      "\n",
      "Overall Class Quality and Noise across your dataset (below)\n",
      "------------------------------------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Label Issues</th>\n",
       "      <th>Inverse Label Issues</th>\n",
       "      <th>Label Noise</th>\n",
       "      <th>Inverse Label Noise</th>\n",
       "      <th>Label Quality Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.759036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>34</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>0.182353</td>\n",
       "      <td>0.236264</td>\n",
       "      <td>0.817647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>0.165563</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.834437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.844828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.902439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>0.077844</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.922156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Name  Class Index  Label Issues  Inverse Label Issues  Label Noise  \\\n",
       "0           3            3            40                    30     0.240964   \n",
       "1           5            5            35                    34     0.217391   \n",
       "2           4            4            31                    43     0.182353   \n",
       "3           6            6            25                    15     0.165563   \n",
       "4           0            0            27                    12     0.155172   \n",
       "5           2            2            16                    20     0.097561   \n",
       "6           1            1            13                    33     0.077844   \n",
       "\n",
       "   Inverse Label Noise  Label Quality Score  \n",
       "0             0.192308             0.759036  \n",
       "1             0.212500             0.782609  \n",
       "2             0.236264             0.817647  \n",
       "3             0.106383             0.834437  \n",
       "4             0.075472             0.844828  \n",
       "5             0.119048             0.902439  \n",
       "6             0.176471             0.922156  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Overlap. In some cases, you may want to merge classes in the top rows (below)\n",
      "-----------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Name A</th>\n",
       "      <th>Class Name B</th>\n",
       "      <th>Class Index A</th>\n",
       "      <th>Class Index B</th>\n",
       "      <th>Num Overlapping Examples</th>\n",
       "      <th>Joint Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>0.023417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.017346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.013010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.013010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.012142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.008673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.008673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.007806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.007806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.006071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.006071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.006071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class Name A  Class Name B  Class Index A  Class Index B  \\\n",
       "0              4             5              4              5   \n",
       "1              3             5              3              5   \n",
       "2              1             4              1              4   \n",
       "3              3             4              3              4   \n",
       "4              0             3              0              3   \n",
       "5              2             6              2              6   \n",
       "6              5             6              5              6   \n",
       "7              1             3              1              3   \n",
       "8              0             4              0              4   \n",
       "9              1             6              1              6   \n",
       "10             2             3              2              3   \n",
       "11             1             2              1              2   \n",
       "12             0             1              0              1   \n",
       "13             4             6              4              6   \n",
       "14             2             5              2              5   \n",
       "15             3             6              3              6   \n",
       "16             0             2              0              2   \n",
       "17             0             5              0              5   \n",
       "18             2             4              2              4   \n",
       "19             0             6              0              6   \n",
       "20             1             5              1              5   \n",
       "\n",
       "    Num Overlapping Examples  Joint Probability  \n",
       "0                         27           0.023417  \n",
       "1                         20           0.017346  \n",
       "2                         15           0.013010  \n",
       "3                         15           0.013010  \n",
       "4                         14           0.012142  \n",
       "5                         10           0.008673  \n",
       "6                         10           0.008673  \n",
       "7                          9           0.007806  \n",
       "8                          9           0.007806  \n",
       "9                          7           0.006071  \n",
       "10                         7           0.006071  \n",
       "11                         7           0.006071  \n",
       "12                         5           0.004337  \n",
       "13                         5           0.004337  \n",
       "14                         5           0.004337  \n",
       "15                         5           0.004337  \n",
       "16                         4           0.003469  \n",
       "17                         4           0.003469  \n",
       "18                         3           0.002602  \n",
       "19                         3           0.002602  \n",
       "20                         3           0.002602  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * Overall, about 11% (122 of the 1,153) labels in your dataset have potential issues.\n",
      " ** The overall label health score for this dataset is: 0.89.\n",
      "\n",
      "Generated with <3 from Cleanlab.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "label_print(model, '../data/preprocess/ascii_ratio_higher_20_mlm_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_text: 메시 · 호날두 ·의FFA리그 올해의 축구 팀에 공식 선정 .. 한국의 선수는 제로\n",
      "label_text: 5\n",
      "-------------------------------------------------\n",
      "input_text: 경기의 첫 번째 활약은 센 투 업하다 ..\n",
      "label_text: 3\n",
      "-------------------------------------------------\n",
      "input_text: 오늘은안당 안가는 아나.. 與 [UNK] 검 [UNK] [UNK] [UNK] [UNK] 先 처리 대통령 카드 안 안을 [UNK]다\n",
      "label_text: 3\n",
      "-------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "|  Generating a Cleanlab Dataset Health Summary          |\n",
      "|   for your dataset with 1,153 examples and 7 classes.  |\n",
      "|  Note, Cleanlab is not a medical doctor... yet.        |\n",
      "----------------------------------------------------------\n",
      "\n",
      "Overall Class Quality and Noise across your dataset (below)\n",
      "------------------------------------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Label Issues</th>\n",
       "      <th>Inverse Label Issues</th>\n",
       "      <th>Label Noise</th>\n",
       "      <th>Inverse Label Noise</th>\n",
       "      <th>Label Quality Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>0.301205</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.698795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>55</td>\n",
       "      <td>0.248447</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.751553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>56</td>\n",
       "      <td>0.229412</td>\n",
       "      <td>0.299465</td>\n",
       "      <td>0.770588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>0.218543</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>22</td>\n",
       "      <td>0.218391</td>\n",
       "      <td>0.139241</td>\n",
       "      <td>0.781609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>0.115854</td>\n",
       "      <td>0.104938</td>\n",
       "      <td>0.884146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>0.047904</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>0.952096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Name  Class Index  Label Issues  Inverse Label Issues  Label Noise  \\\n",
       "0           3            3            50                    29     0.301205   \n",
       "1           5            5            40                    55     0.248447   \n",
       "2           4            4            39                    56     0.229412   \n",
       "3           6            6            33                    18     0.218543   \n",
       "4           0            0            38                    22     0.218391   \n",
       "5           2            2            19                    17     0.115854   \n",
       "6           1            1             8                    30     0.047904   \n",
       "\n",
       "   Inverse Label Noise  Label Quality Score  \n",
       "0             0.200000             0.698795  \n",
       "1             0.312500             0.751553  \n",
       "2             0.299465             0.770588  \n",
       "3             0.132353             0.781457  \n",
       "4             0.139241             0.781609  \n",
       "5             0.104938             0.884146  \n",
       "6             0.158730             0.952096  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Overlap. In some cases, you may want to merge classes in the top rows (below)\n",
      "-----------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Name A</th>\n",
       "      <th>Class Name B</th>\n",
       "      <th>Class Index A</th>\n",
       "      <th>Class Index B</th>\n",
       "      <th>Num Overlapping Examples</th>\n",
       "      <th>Joint Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>0.031223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.019948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.019948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.013877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0.013877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.012142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.012142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.009540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.009540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.006938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.006938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.006071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class Name A  Class Name B  Class Index A  Class Index B  \\\n",
       "0              4             5              4              5   \n",
       "1              3             5              3              5   \n",
       "2              0             3              0              3   \n",
       "3              3             4              3              4   \n",
       "4              5             6              5              6   \n",
       "5              1             4              1              4   \n",
       "6              0             4              0              4   \n",
       "7              0             5              0              5   \n",
       "8              4             6              4              6   \n",
       "9              2             6              2              6   \n",
       "10             1             6              1              6   \n",
       "11             0             2              0              2   \n",
       "12             2             5              2              5   \n",
       "13             3             6              3              6   \n",
       "14             2             3              2              3   \n",
       "15             1             3              1              3   \n",
       "16             1             2              1              2   \n",
       "17             2             4              2              4   \n",
       "18             0             1              0              1   \n",
       "19             1             5              1              5   \n",
       "20             0             6              0              6   \n",
       "\n",
       "    Num Overlapping Examples  Joint Probability  \n",
       "0                         36           0.031223  \n",
       "1                         23           0.019948  \n",
       "2                         23           0.019948  \n",
       "3                         16           0.013877  \n",
       "4                         16           0.013877  \n",
       "5                         14           0.012142  \n",
       "6                         14           0.012142  \n",
       "7                         11           0.009540  \n",
       "8                         11           0.009540  \n",
       "9                          8           0.006938  \n",
       "10                         8           0.006938  \n",
       "11                         7           0.006071  \n",
       "12                         6           0.005204  \n",
       "13                         6           0.005204  \n",
       "14                         6           0.005204  \n",
       "15                         5           0.004337  \n",
       "16                         5           0.004337  \n",
       "17                         4           0.003469  \n",
       "18                         3           0.002602  \n",
       "19                         3           0.002602  \n",
       "20                         2           0.001735  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * Overall, about 13% (148 of the 1,153) labels in your dataset have potential issues.\n",
      " ** The overall label health score for this dataset is: 0.87.\n",
      "\n",
      "Generated with <3 from Cleanlab.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_print(model, '../data/preprocess/ascii_ratio_higher_20_mlm_btm_train.csv')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
