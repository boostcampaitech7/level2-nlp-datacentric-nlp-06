{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.2)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.67.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers evaluate scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 로드 및 설정\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import evaluate\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ================================================\n",
    "print(\"데이터셋 로드 및 설정\")\n",
    "# ================================================\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# 디바이스 설정 (GPU가 사용 가능하면 GPU를 사용하고, 그렇지 않으면 CPU 사용)\n",
    "#DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model_name = 'klue/bert-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 데이터셋 로드\n",
    "df = pd.read_csv('/data/ephemeral/home/data/train.csv')\n",
    "\n",
    "dataset = Dataset.from_pandas(df.head(500))\n",
    "\n",
    "# 데이터셋을 데이터프레임으로 변환\n",
    "train_ED = pd.DataFrame(df)\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# 데이터셋에 인덱스 컬럼 추가\n",
    "df = df.reset_index().rename(columns={'index': 'idx'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_train_00001</td>\n",
       "      <td>K찰.국DLwo 로L3한N% 회장 2 T0&amp;}송=</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>m 김정) 자주통일 새,?r열1나가야1보</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ynat-v1_train_00003</td>\n",
       "      <td>갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>pI美대선I앞두고 R2fr단 발] $비해 감시 강화</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>ynat-v1_train_02795</td>\n",
       "      <td>트럼프 폭스뉴스 앵커들 충성도 점수매겨…10점만점에 12점도</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>ynat-v1_train_02796</td>\n",
       "      <td>삼성 갤럭시S9 정식 출시 첫 주말 이통시장 잠잠</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>ynat-v1_train_02797</td>\n",
       "      <td>텔레그램+한D 등h亞서 2시간H다운…C버T정gf39종!2보</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>ynat-v1_train_02798</td>\n",
       "      <td>인터뷰 류현진 친구에게 안타 맞는 것 싫어해…승부는 냉정</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>ynat-v1_train_02799</td>\n",
       "      <td>지능정보사회 대비 국가 종합대책 마련</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID                               text  target\n",
       "0     ynat-v1_train_00000   정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보       4\n",
       "1     ynat-v1_train_00001        K찰.국DLwo 로L3한N% 회장 2 T0&}송=       3\n",
       "2     ynat-v1_train_00002             m 김정) 자주통일 새,?r열1나가야1보       2\n",
       "3     ynat-v1_train_00003      갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩       5\n",
       "4     ynat-v1_train_00004       pI美대선I앞두고 R2fr단 발] $비해 감시 강화       6\n",
       "...                   ...                                ...     ...\n",
       "2795  ynat-v1_train_02795  트럼프 폭스뉴스 앵커들 충성도 점수매겨…10점만점에 12점도       6\n",
       "2796  ynat-v1_train_02796        삼성 갤럭시S9 정식 출시 첫 주말 이통시장 잠잠       2\n",
       "2797  ynat-v1_train_02797   텔레그램+한D 등h亞서 2시간H다운…C버T정gf39종!2보       4\n",
       "2798  ynat-v1_train_02798    인터뷰 류현진 친구에게 안타 맞는 것 싫어해…승부는 냉정       1\n",
       "2799  ynat-v1_train_02799               지능정보사회 대비 국가 종합대책 마련       4\n",
       "\n",
       "[2800 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#구두점을 제거 했을때 예측결과가 잘 나올까에 대한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 구두점 비율: 7.59%\n"
     ]
    }
   ],
   "source": [
    "# 구두점 문자 정의\n",
    "punctuation = string.punctuation\n",
    "\n",
    "# 구두점 개수 계산 함수\n",
    "def count_punctuation(text):\n",
    "    return sum(1 for char in text if char in punctuation)\n",
    "\n",
    "# DataFrame의 텍스트 열에 함수 적용 (예: 'text' 열이 텍스트 데이터를 포함한다고 가정)\n",
    "df['punctuation_count'] = df['text'].apply(count_punctuation)\n",
    "\n",
    "# 전체 문자 수 계산\n",
    "df['total_chars'] = df['text'].str.len()\n",
    "\n",
    "# 구두점 비율 계산\n",
    "total_punctuation = df['punctuation_count'].sum()\n",
    "total_chars = df['total_chars'].sum()\n",
    "\n",
    "punctuation_ratio = total_punctuation / total_chars\n",
    "\n",
    "print(f\"전체 구두점 비율: {punctuation_ratio:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>total_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>m 김정) 자주통일 새,?r열1나가야1보</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ynat-v1_train_00003</td>\n",
       "      <td>갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>pI美대선I앞두고 R2fr단 발] $비해 감시 강화</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>ynat-v1_train_00005</td>\n",
       "      <td>美성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>494</td>\n",
       "      <td>ynat-v1_train_00494</td>\n",
       "      <td>대형서점엔=없uDtOJ네yC과 손}는 b판사들</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>ynat-v1_train_00495</td>\n",
       "      <td>o시티·리버=L3·4ea확;…아스널 20년만에D\"스리그Y좌절</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>ynat-v1_train_00496</td>\n",
       "      <td>조소앙이 쓴 독립운I#1평전 유방z *Ep역</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>ynat-v1_train_00497</td>\n",
       "      <td>김영란법 때문에E애플 t이폰 초청70못받7 r국 언.</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>ynat-v1_train_00499</td>\n",
       "      <td>신:p(피U 로y의 시-</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                   ID                               text  target  \\\n",
       "0      0  ynat-v1_train_00000   정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보       4   \n",
       "2      2  ynat-v1_train_00002             m 김정) 자주통일 새,?r열1나가야1보       2   \n",
       "3      3  ynat-v1_train_00003      갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩       5   \n",
       "4      4  ynat-v1_train_00004       pI美대선I앞두고 R2fr단 발] $비해 감시 강화       6   \n",
       "5      5  ynat-v1_train_00005     美성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다       0   \n",
       "..   ...                  ...                                ...     ...   \n",
       "494  494  ynat-v1_train_00494          대형서점엔=없uDtOJ네yC과 손}는 b판사들       0   \n",
       "495  495  ynat-v1_train_00495  o시티·리버=L3·4ea확;…아스널 20년만에D\"스리그Y좌절       1   \n",
       "496  496  ynat-v1_train_00496           조소앙이 쓴 독립운I#1평전 유방z *Ep역       0   \n",
       "497  497  ynat-v1_train_00497      김영란법 때문에E애플 t이폰 초청70못받7 r국 언.       3   \n",
       "499  499  ynat-v1_train_00499                      신:p(피U 로y의 시-       0   \n",
       "\n",
       "     punctuation_count  total_chars  \n",
       "0                    3           32  \n",
       "2                    3           22  \n",
       "3                    0           29  \n",
       "4                    2           28  \n",
       "5                    0           30  \n",
       "..                 ...          ...  \n",
       "494                  2           25  \n",
       "495                  3           33  \n",
       "496                  2           24  \n",
       "497                  1           29  \n",
       "499                  3           13  \n",
       "\n",
       "[362 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df[df['punctuation_count'] <= 3]\n",
    "\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 제거 후 자주 나오는 단어 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# 한국어 불용어 리스트 (예시, 필요에 따라 확장 가능)\n",
    "korean_stopwords = set(['은', '는', '이', '가', '을', '를', '의', '에', '에서', '로', '으로', '과', '와', '도', '만', '에게', '께', '한테', '보다', '라고', '이라고', '으로서', '같이', '처럼', '만큼'])\n",
    "\n",
    "# 정규표현식 패턴 정의\n",
    "korean_pattern = re.compile('[가-힣]{2,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대통령: 8\n",
      "억원: 8\n",
      "이란: 7\n",
      "개발: 6\n",
      "감독: 6\n",
      "내년: 6\n",
      "분기: 5\n",
      "공개: 5\n",
      "게시판: 4\n",
      "목소리: 4\n",
      "영상: 4\n",
      "네이버: 4\n",
      "올해: 4\n",
      "삼성: 4\n",
      "김정은: 4\n",
      "홍콩: 4\n",
      "세계: 4\n",
      "협력: 4\n",
      "우리카드: 3\n",
      "아이폰: 3\n",
      "성공: 3\n",
      "아시안게임: 3\n",
      "다시: 3\n",
      "증가: 3\n",
      "복귀: 3\n",
      "발견: 3\n",
      "스마트폰: 3\n",
      "류현진: 3\n",
      "모바일: 3\n",
      "개막: 3\n",
      "신청: 3\n",
      "여행: 3\n",
      "연속: 3\n",
      "방문: 3\n",
      "프로농구: 3\n",
      "교체: 3\n",
      "구글: 3\n",
      "출시: 3\n",
      "남북: 3\n",
      "만에: 3\n",
      "민주: 3\n",
      "신간: 3\n",
      "애플: 3\n",
      "개최: 3\n",
      "정상: 3\n",
      "환영: 3\n",
      "그래픽: 3\n",
      "논란: 3\n",
      "김정: 2\n",
      "주말: 2\n"
     ]
    }
   ],
   "source": [
    "def process_text(text):\n",
    "    # 영어와 특수문자 제거, 소문자 변환\n",
    "    text = re.sub(r'[a-zA-Z0-9\\W]+', ' ', text.lower())\n",
    "    \n",
    "    # 한글 단어 추출 (2글자 이상)\n",
    "    words = korean_pattern.findall(text)\n",
    "    \n",
    "    # 불용어 제거\n",
    "    words = [word for word in words if word not in korean_stopwords]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# 모든 텍스트에서 단어 추출 및 빈도 계산\n",
    "all_words = []\n",
    "for text in df_filtered['text']:\n",
    "    all_words.extend(process_text(text))\n",
    "\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# 상위 50개 단어 추출\n",
    "top_50_words = word_counts.most_common(50)\n",
    "\n",
    "# 결과 출력\n",
    "for word, count in top_50_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googletrans==3.1.0a0 in /opt/conda/lib/python3.10/site-packages (3.1.0a0)\n",
      "Requirement already satisfied: httpx==0.13.3 in /opt/conda/lib/python3.10/site-packages (from googletrans==3.1.0a0) (0.13.3)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2024.8.30)\n",
      "Requirement already satisfied: hstspreload in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2024.11.1)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.3.1)\n",
      "Requirement already satisfied: chardet==3.* in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in /opt/conda/lib/python3.10/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in /opt/conda/lib/python3.10/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in /opt/conda/lib/python3.10/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in /opt/conda/lib/python3.10/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install googletrans==3.1.0a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_792453/124184933.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['translated_text'] = df_filtered['text'].apply(lambda x: translate_non_korean(x)[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  text                       translated_text  \\\n",
      "0     정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보   정나 :파1 미사와 함께 KT( 이용기간 에이 단] 큐분종U2보   \n",
      "2               m 김정) 자주통일 새,?r열1나가야1보            중 김정) 자주통일 새,?아르 자형열1나가야1보   \n",
      "3        갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩         갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩   \n",
      "4         pI美대선I앞두고 R2fr단 발] $비해 감시 강화          피메이대선나앞두고 R2fr단 발] $비해 감시 강화   \n",
      "5       美성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다     아름다운성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다   \n",
      "..                                 ...                                   ...   \n",
      "494          대형서점엔=없uDtOJ네yC과 손}는 b판사들             대형서점엔=없uDtOJ네yC과 손}는 비판사들   \n",
      "495  o시티·리버=L3·4ea확;…아스널 20년만에D\"스리그Y좌절  그만큼시티·리버=L3·4개확;…아스널 20년만에디\"스리그그리고좌절   \n",
      "496           조소앙이 쓴 독립운I#1평전 유방z *Ep역            조소앙이 쓴 독립운나#1평전 유방와 함께 *엡역   \n",
      "497      김영란법 때문에E애플 t이폰 초청70못받7 r국 언.   김영란법 때문에그리고애플 티이폰 초청70못받7 아르 자형국 언.   \n",
      "499                      신:p(피U 로y의 시-                      신:피(피안에 로그리고의 시-   \n",
      "\n",
      "                                      translated_words  \n",
      "0    {'i': '나', ':': ':', '1': '1', 'z': '와 함께', 'K...  \n",
      "2     {'m': '중', ')': ')', ',?r': ',?아르 자형', '1': '1'}  \n",
      "3                     {'8': '8', '27': '27', '…': '…'}  \n",
      "4    {'pI美': '피메이', 'I': '나', 'R2fr': 'R2fr', ']': ...  \n",
      "5          {'美': '아름다운', '6': '6', '1': '1', '·': '·'}  \n",
      "..                                                 ...  \n",
      "494  {'=': '=', 'uDtOJ': 'uDtOJ', 'yC': 'yC', '}': ...  \n",
      "495  {'o': '그만큼', '·': '·', '=L3·4ea': '=L3·4개', ';...  \n",
      "496           {'I#1': '나#1', 'z': '와 함께', '*Ep': '*엡'}  \n",
      "497  {'E': '그리고', 't': '티', '70': '70', '7': '7', '...  \n",
      "499    {':p(': ':피(', 'U': '안에', 'y': '그리고', '-': '-'}  \n",
      "\n",
      "[362 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_792453/124184933.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['translated_words'] = df_filtered['text'].apply(lambda x: translate_non_korean(x)[1])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from googletrans import Translator\n",
    "\n",
    "# 번역기 초기화\n",
    "translator = Translator()\n",
    "\n",
    "# 한글 문자 범위를 정의하는 정규표현식\n",
    "korean_pattern = re.compile('[가-힣]+')\n",
    "\n",
    "def translate_non_korean(text):\n",
    "    # 한글이 아닌 문자들을 찾아 리스트로 만듭니다\n",
    "    non_korean = re.findall(r'[^\\s가-힣]+', text)\n",
    "    \n",
    "    translated_words = {}\n",
    "    for word in non_korean:\n",
    "        try:\n",
    "            # 한글이 아닌 단어를 한글로 번역\n",
    "            translated = translator.translate(word, dest='ko').text\n",
    "            translated_words[word] = translated\n",
    "            # 원본 텍스트에서 번역된 단어로 교체\n",
    "            text = text.replace(word, translated)\n",
    "        except:\n",
    "            # 번역 실패 시 원래 단어 유지\n",
    "            pass\n",
    "    \n",
    "    return text, translated_words\n",
    "\n",
    "# df_filtered의 'text' 열에 대해 번역 함수 적용\n",
    "df_filtered['translated_text'] = df_filtered['text'].apply(lambda x: translate_non_korean(x)[0])\n",
    "df_filtered['translated_words'] = df_filtered['text'].apply(lambda x: translate_non_korean(x)[1])\n",
    "\n",
    "# 결과 출력\n",
    "print(df_filtered[['text', 'translated_text', 'translated_words']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>total_chars</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>translated_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>정나 :파1 미사와 함께 KT( 이용기간 에이 단] 큐분종U2보</td>\n",
       "      <td>{'i': '나', ':': ':', '1': '1', 'z': '와 함께', 'K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>m 김정) 자주통일 새,?r열1나가야1보</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>중 김정) 자주통일 새,?아르 자형열1나가야1보</td>\n",
       "      <td>{'m': '중', ')': ')', ',?r': ',?아르 자형', '1': '1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ynat-v1_train_00003</td>\n",
       "      <td>갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩</td>\n",
       "      <td>{'8': '8', '27': '27', '…': '…'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>pI美대선I앞두고 R2fr단 발] $비해 감시 강화</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>피메이대선나앞두고 R2fr단 발] $비해 감시 강화</td>\n",
       "      <td>{'pI美': '피메이', 'I': '나', 'R2fr': 'R2fr', ']': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>ynat-v1_train_00005</td>\n",
       "      <td>美성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>아름다운성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다</td>\n",
       "      <td>{'美': '아름다운', '6': '6', '1': '1', '·': '·'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>494</td>\n",
       "      <td>ynat-v1_train_00494</td>\n",
       "      <td>대형서점엔=없uDtOJ네yC과 손}는 b판사들</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>대형서점엔=없uDtOJ네yC과 손}는 비판사들</td>\n",
       "      <td>{'=': '=', 'uDtOJ': 'uDtOJ', 'yC': 'yC', '}': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>ynat-v1_train_00495</td>\n",
       "      <td>o시티·리버=L3·4ea확;…아스널 20년만에D\"스리그Y좌절</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>그만큼시티·리버=L3·4개확;…아스널 20년만에디\"스리그그리고좌절</td>\n",
       "      <td>{'o': '그만큼', '·': '·', '=L3·4ea': '=L3·4개', ';...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>ynat-v1_train_00496</td>\n",
       "      <td>조소앙이 쓴 독립운I#1평전 유방z *Ep역</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>조소앙이 쓴 독립운나#1평전 유방와 함께 *엡역</td>\n",
       "      <td>{'I#1': '나#1', 'z': '와 함께', '*Ep': '*엡'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>ynat-v1_train_00497</td>\n",
       "      <td>김영란법 때문에E애플 t이폰 초청70못받7 r국 언.</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>김영란법 때문에그리고애플 티이폰 초청70못받7 아르 자형국 언.</td>\n",
       "      <td>{'E': '그리고', 't': '티', '70': '70', '7': '7', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>ynat-v1_train_00499</td>\n",
       "      <td>신:p(피U 로y의 시-</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>신:피(피안에 로그리고의 시-</td>\n",
       "      <td>{':p(': ':피(', 'U': '안에', 'y': '그리고', '-': '-'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                   ID                               text  target  \\\n",
       "0      0  ynat-v1_train_00000   정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보       4   \n",
       "2      2  ynat-v1_train_00002             m 김정) 자주통일 새,?r열1나가야1보       2   \n",
       "3      3  ynat-v1_train_00003      갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩       5   \n",
       "4      4  ynat-v1_train_00004       pI美대선I앞두고 R2fr단 발] $비해 감시 강화       6   \n",
       "5      5  ynat-v1_train_00005     美성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다       0   \n",
       "..   ...                  ...                                ...     ...   \n",
       "494  494  ynat-v1_train_00494          대형서점엔=없uDtOJ네yC과 손}는 b판사들       0   \n",
       "495  495  ynat-v1_train_00495  o시티·리버=L3·4ea확;…아스널 20년만에D\"스리그Y좌절       1   \n",
       "496  496  ynat-v1_train_00496           조소앙이 쓴 독립운I#1평전 유방z *Ep역       0   \n",
       "497  497  ynat-v1_train_00497      김영란법 때문에E애플 t이폰 초청70못받7 r국 언.       3   \n",
       "499  499  ynat-v1_train_00499                      신:p(피U 로y의 시-       0   \n",
       "\n",
       "     punctuation_count  total_chars                       translated_text  \\\n",
       "0                    3           32   정나 :파1 미사와 함께 KT( 이용기간 에이 단] 큐분종U2보   \n",
       "2                    3           22            중 김정) 자주통일 새,?아르 자형열1나가야1보   \n",
       "3                    0           29         갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩   \n",
       "4                    2           28          피메이대선나앞두고 R2fr단 발] $비해 감시 강화   \n",
       "5                    0           30     아름다운성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다   \n",
       "..                 ...          ...                                   ...   \n",
       "494                  2           25             대형서점엔=없uDtOJ네yC과 손}는 비판사들   \n",
       "495                  3           33  그만큼시티·리버=L3·4개확;…아스널 20년만에디\"스리그그리고좌절   \n",
       "496                  2           24            조소앙이 쓴 독립운나#1평전 유방와 함께 *엡역   \n",
       "497                  1           29   김영란법 때문에그리고애플 티이폰 초청70못받7 아르 자형국 언.   \n",
       "499                  3           13                      신:피(피안에 로그리고의 시-   \n",
       "\n",
       "                                      translated_words  \n",
       "0    {'i': '나', ':': ':', '1': '1', 'z': '와 함께', 'K...  \n",
       "2     {'m': '중', ')': ')', ',?r': ',?아르 자형', '1': '1'}  \n",
       "3                     {'8': '8', '27': '27', '…': '…'}  \n",
       "4    {'pI美': '피메이', 'I': '나', 'R2fr': 'R2fr', ']': ...  \n",
       "5          {'美': '아름다운', '6': '6', '1': '1', '·': '·'}  \n",
       "..                                                 ...  \n",
       "494  {'=': '=', 'uDtOJ': 'uDtOJ', 'yC': 'yC', '}': ...  \n",
       "495  {'o': '그만큼', '·': '·', '=L3·4ea': '=L3·4개', ';...  \n",
       "496           {'I#1': '나#1', 'z': '와 함께', '*Ep': '*엡'}  \n",
       "497  {'E': '그리고', 't': '티', '70': '70', '7': '7', '...  \n",
       "499    {':p(': ':피(', 'U': '안에', 'y': '그리고', '-': '-'}  \n",
       "\n",
       "[362 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "탐지된 외국어:\n",
      "- no\n",
      "- vi\n",
      "- cy\n",
      "- English\n",
      "- id\n",
      "- de\n",
      "- pl\n",
      "- ca\n",
      "- ro\n",
      "- lt\n",
      "- da\n",
      "- fr\n",
      "- ko\n",
      "- sk\n",
      "- es\n",
      "- tl\n",
      "- lv\n",
      "- et\n",
      "- it\n",
      "- sv\n",
      "- sq\n",
      "- fi\n",
      "- cs\n",
      "- so\n",
      "- sw\n",
      "- hr\n",
      "- sl\n",
      "- af\n",
      "- pt\n",
      "- hu\n",
      "- Chinese\n",
      "\n",
      "언어별 출현 빈도:\n",
      "detected_languages\n",
      "English    185\n",
      "ko          37\n",
      "Chinese     36\n",
      "sw          20\n",
      "de          17\n",
      "pl          17\n",
      "ca          15\n",
      "so          14\n",
      "vi          13\n",
      "sq          11\n",
      "cy          10\n",
      "tl           9\n",
      "no           6\n",
      "id           5\n",
      "pt           5\n",
      "sk           4\n",
      "cs           4\n",
      "es           3\n",
      "sv           3\n",
      "hu           3\n",
      "sl           3\n",
      "it           2\n",
      "ro           2\n",
      "fr           2\n",
      "af           2\n",
      "da           2\n",
      "lv           1\n",
      "lt           1\n",
      "fi           1\n",
      "hr           1\n",
      "et           1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_792453/3969083926.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['detected_languages'] = df_filtered['text'].apply(detect_languages)\n",
      "/tmp/ipykernel_792453/3969083926.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['detected_languages'] = df_filtered['detected_languages'].apply(list)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "def detect_languages(text):\n",
    "    # 한글과 공백을 제외한 문자 추출\n",
    "    non_korean = re.sub(r'[가-힣\\s]', '', text)\n",
    "    \n",
    "    if not non_korean:\n",
    "        return set()\n",
    "    \n",
    "    languages = set()\n",
    "    \n",
    "    # 영어 탐지\n",
    "    if re.search(r'[a-zA-Z]', non_korean):\n",
    "        languages.add('English')\n",
    "    \n",
    "    # 일본어 탐지 (히라가나, 가타카나)\n",
    "    if re.search(r'[\\u3040-\\u30FF]', non_korean):\n",
    "        languages.add('Japanese')\n",
    "    \n",
    "    # 중국어 탐지\n",
    "    if re.search(r'[\\u4E00-\\u9FFF]', non_korean):\n",
    "        languages.add('Chinese')\n",
    "    \n",
    "    # 기타 언어 탐지\n",
    "    try:\n",
    "        other_lang = detect(non_korean)\n",
    "        if other_lang not in ['en', 'ja', 'zh-cn', 'zh-tw']:\n",
    "            languages.add(other_lang)\n",
    "    except LangDetectException:\n",
    "        pass\n",
    "    \n",
    "    return languages\n",
    "\n",
    "# 데이터프레임의 각 행에 대해 언어 탐지 함수 적용\n",
    "df_filtered['detected_languages'] = df_filtered['text'].apply(detect_languages)\n",
    "\n",
    "# 탐지된 모든 언어 목록 생성\n",
    "all_detected_languages = set.union(*df_filtered['detected_languages'])\n",
    "\n",
    "print(\"탐지된 외국어:\")\n",
    "for lang in all_detected_languages:\n",
    "    print(f\"- {lang}\")\n",
    "\n",
    "# set을 리스트로 변환\n",
    "df_filtered['detected_languages'] = df_filtered['detected_languages'].apply(list)\n",
    "\n",
    "# 각 언어별 출현 빈도 계산\n",
    "language_counts = df_filtered['detected_languages'].explode().value_counts()\n",
    "\n",
    "print(\"\\n언어별 출현 빈도:\")\n",
    "print(language_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86075564ed8498d895fe5b7375c4de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:  21%|##1       | 409M/1.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5201da33e162441f913caf544857c96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/233 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ea4d2cc3ca40e3b9bb229be2981369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/298 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbb440f97b04656b115001a2486b14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/3.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbfd271635c4d5988544f8c5a5f8be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65921708c444e2e94f88b7aa367542f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_792453/2079577929.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['Back_Translation_text'] = \"\"\n",
      "/tmp/ipykernel_792453/2079577929.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['Back_Translation_words'] = \"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  text  \\\n",
      "0     정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보   \n",
      "2               m 김정) 자주통일 새,?r열1나가야1보   \n",
      "3        갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩   \n",
      "4         pI美대선I앞두고 R2fr단 발] $비해 감시 강화   \n",
      "5       美성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다   \n",
      "..                                 ...   \n",
      "494          대형서점엔=없uDtOJ네yC과 손}는 b판사들   \n",
      "495  o시티·리버=L3·4ea확;…아스널 20년만에D\"스리그Y좌절   \n",
      "496           조소앙이 쓴 독립운I#1평전 유방z *Ep역   \n",
      "497      김영란법 때문에E애플 t이폰 초청70못받7 r국 언.   \n",
      "499                      신:p(피U 로y의 시-   \n",
      "\n",
      "                                 Back_Translation_text  \\\n",
      "0                                  P1 MISAZ KT (U2E 만)   \n",
      "2                                           나는 새인가요? 1   \n",
      "3                    GNU 8 주말에 열리는 27,000...시장은 불법 보조금   \n",
      "4       R2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2   \n",
      "5                           결혼한 여성 6명 중 1명은 결코 빚을 잃었다.   \n",
      "..                                                 ...   \n",
      "494                                        판사와 판사가 있다.   \n",
      "495                  oCity-River=L3·4ea확; 20년 안에 아르헨티나   \n",
      "496          The Independent I#1 Peace Breastz 에프 스테이션   \n",
      "497  Eaple Tifon에 대한 Kim 영국의 법률은 70을 7 개의 방사선을 받지 않...   \n",
      "499                                           P (왕의 P)   \n",
      "\n",
      "                                Back_Translation_words  \n",
      "0    {'정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보': 'P1 MISAZ...  \n",
      "2             {'m 김정) 자주통일 새,?r열1나가야1보': '나는 새인가요? 1'}  \n",
      "3    {'갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩': 'GNU 8 주말에 열...  \n",
      "4    {'pI美대선I앞두고 R2fr단 발] $비해 감시 강화': 'R2F2F2F2F2F2...  \n",
      "5    {'美성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다': '결혼한 여성 6명 ...  \n",
      "..                                                 ...  \n",
      "494       {'대형서점엔=없uDtOJ네yC과 손}는 b판사들': '판사와 판사가 있다.'}  \n",
      "495  {'o시티·리버=L3·4ea확;…아스널 20년만에D\"스리그Y좌절': 'oCity-R...  \n",
      "496  {'조소앙이 쓴 독립운I#1평전 유방z *Ep역': 'The Independent ...  \n",
      "497  {'김영란법 때문에E애플 t이폰 초청70못받7 r국 언.': 'Eaple Tifon...  \n",
      "499                      {'신:p(피U 로y의 시-': 'P (왕의 P)'}  \n",
      "\n",
      "[362 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "import torch\n",
    "\n",
    "# M2M100 모델 및 토크나이저 로드\n",
    "model_name = \"facebook/m2m100_418M\"\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "def back_translate(text, src_lang=\"ko\", tgt_lang=\"en\"):\n",
    "    # 한국어 -> 영어 번역\n",
    "    tokenizer.src_lang = src_lang\n",
    "    encoded = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    generated_tokens = model.generate(**encoded, forced_bos_token_id=tokenizer.get_lang_id(tgt_lang))\n",
    "    intermediate = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "    \n",
    "    # 영어 -> 한국어 번역 (Back Translation)\n",
    "    tokenizer.src_lang = tgt_lang\n",
    "    encoded = tokenizer(intermediate, return_tensors=\"pt\").to(device)\n",
    "    generated_tokens = model.generate(**encoded, forced_bos_token_id=tokenizer.get_lang_id(src_lang))\n",
    "    back_translated = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "    \n",
    "    return back_translated, intermediate\n",
    "\n",
    "# Back Translation 수행 및 새 컬럼 추가\n",
    "df_filtered['Back_Translation_text'] = \"\"\n",
    "df_filtered['Back_Translation_words'] = \"\"\n",
    "\n",
    "for idx, row in df_filtered.iterrows():\n",
    "    back_translated, intermediate = back_translate(row['text'])\n",
    "    df_filtered.at[idx, 'Back_Translation_text'] = back_translated\n",
    "    df_filtered.at[idx, 'Back_Translation_words'] = {row['text']: back_translated}\n",
    "\n",
    "print(df_filtered[['text', 'Back_Translation_text', 'Back_Translation_words']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>total_chars</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>translated_words</th>\n",
       "      <th>foreign_chars</th>\n",
       "      <th>detected_languages</th>\n",
       "      <th>Back_Translation_text</th>\n",
       "      <th>Back_Translation_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>정나 :파1 미사와 함께 KT( 이용기간 에이 단] 큐분종U2보</td>\n",
       "      <td>{'i': '나', ':': ':', '1': '1', 'z': '와 함께', 'K...</td>\n",
       "      <td>(:KQTU]eiz</td>\n",
       "      <td>[English, sq]</td>\n",
       "      <td>P1 MISAZ KT (U2E 만)</td>\n",
       "      <td>{'정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보': 'P1 MISAZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>m 김정) 자주통일 새,?r열1나가야1보</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>중 김정) 자주통일 새,?아르 자형열1나가야1보</td>\n",
       "      <td>{'m': '중', ')': ')', ',?r': ',?아르 자형', '1': '1'}</td>\n",
       "      <td>)mr</td>\n",
       "      <td>[cy, English]</td>\n",
       "      <td>나는 새인가요? 1</td>\n",
       "      <td>{'m 김정) 자주통일 새,?r열1나가야1보': '나는 새인가요? 1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ynat-v1_train_00003</td>\n",
       "      <td>갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩</td>\n",
       "      <td>{'8': '8', '27': '27', '…': '…'}</td>\n",
       "      <td>…</td>\n",
       "      <td>[]</td>\n",
       "      <td>GNU 8 주말에 열리는 27,000...시장은 불법 보조금</td>\n",
       "      <td>{'갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩': 'GNU 8 주말에 열...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>pI美대선I앞두고 R2fr단 발] $비해 감시 강화</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>피메이대선나앞두고 R2fr단 발] $비해 감시 강화</td>\n",
       "      <td>{'pI美': '피메이', 'I': '나', 'R2fr': 'R2fr', ']': ...</td>\n",
       "      <td>$IR]fpr美</td>\n",
       "      <td>[no, English, Chinese]</td>\n",
       "      <td>R2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2</td>\n",
       "      <td>{'pI美대선I앞두고 R2fr단 발] $비해 감시 강화': 'R2F2F2F2F2F2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>ynat-v1_train_00005</td>\n",
       "      <td>美성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>아름다운성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다</td>\n",
       "      <td>{'美': '아름다운', '6': '6', '1': '1', '·': '·'}</td>\n",
       "      <td>·美</td>\n",
       "      <td>[ko, Chinese]</td>\n",
       "      <td>결혼한 여성 6명 중 1명은 결코 빚을 잃었다.</td>\n",
       "      <td>{'美성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다': '결혼한 여성 6명 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>494</td>\n",
       "      <td>ynat-v1_train_00494</td>\n",
       "      <td>대형서점엔=없uDtOJ네yC과 손}는 b판사들</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>대형서점엔=없uDtOJ네yC과 손}는 비판사들</td>\n",
       "      <td>{'=': '=', 'uDtOJ': 'uDtOJ', 'yC': 'yC', '}': ...</td>\n",
       "      <td>=CDJObtuy}</td>\n",
       "      <td>[cy, English]</td>\n",
       "      <td>판사와 판사가 있다.</td>\n",
       "      <td>{'대형서점엔=없uDtOJ네yC과 손}는 b판사들': '판사와 판사가 있다.'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>ynat-v1_train_00495</td>\n",
       "      <td>o시티·리버=L3·4ea확;…아스널 20년만에D\"스리그Y좌절</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>그만큼시티·리버=L3·4개확;…아스널 20년만에디\"스리그그리고좌절</td>\n",
       "      <td>{'o': '그만큼', '·': '·', '=L3·4ea': '=L3·4개', ';...</td>\n",
       "      <td>\";=DLYaeo·…</td>\n",
       "      <td>[English, ca]</td>\n",
       "      <td>oCity-River=L3·4ea확; 20년 안에 아르헨티나</td>\n",
       "      <td>{'o시티·리버=L3·4ea확;…아스널 20년만에D\"스리그Y좌절': 'oCity-R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>ynat-v1_train_00496</td>\n",
       "      <td>조소앙이 쓴 독립운I#1평전 유방z *Ep역</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>조소앙이 쓴 독립운나#1평전 유방와 함께 *엡역</td>\n",
       "      <td>{'I#1': '나#1', 'z': '와 함께', '*Ep': '*엡'}</td>\n",
       "      <td>#*EIpz</td>\n",
       "      <td>[English, pl]</td>\n",
       "      <td>The Independent I#1 Peace Breastz 에프 스테이션</td>\n",
       "      <td>{'조소앙이 쓴 독립운I#1평전 유방z *Ep역': 'The Independent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>ynat-v1_train_00497</td>\n",
       "      <td>김영란법 때문에E애플 t이폰 초청70못받7 r국 언.</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>김영란법 때문에그리고애플 티이폰 초청70못받7 아르 자형국 언.</td>\n",
       "      <td>{'E': '그리고', 't': '티', '70': '70', '7': '7', '...</td>\n",
       "      <td>Ert</td>\n",
       "      <td>[English, da]</td>\n",
       "      <td>Eaple Tifon에 대한 Kim 영국의 법률은 70을 7 개의 방사선을 받지 않...</td>\n",
       "      <td>{'김영란법 때문에E애플 t이폰 초청70못받7 r국 언.': 'Eaple Tifon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>ynat-v1_train_00499</td>\n",
       "      <td>신:p(피U 로y의 시-</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>신:피(피안에 로그리고의 시-</td>\n",
       "      <td>{':p(': ':피(', 'U': '안에', 'y': '그리고', '-': '-'}</td>\n",
       "      <td>(-:Upy</td>\n",
       "      <td>[English, tl]</td>\n",
       "      <td>P (왕의 P)</td>\n",
       "      <td>{'신:p(피U 로y의 시-': 'P (왕의 P)'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                   ID                               text  target  \\\n",
       "0      0  ynat-v1_train_00000   정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보       4   \n",
       "2      2  ynat-v1_train_00002             m 김정) 자주통일 새,?r열1나가야1보       2   \n",
       "3      3  ynat-v1_train_00003      갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩       5   \n",
       "4      4  ynat-v1_train_00004       pI美대선I앞두고 R2fr단 발] $비해 감시 강화       6   \n",
       "5      5  ynat-v1_train_00005     美성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다       0   \n",
       "..   ...                  ...                                ...     ...   \n",
       "494  494  ynat-v1_train_00494          대형서점엔=없uDtOJ네yC과 손}는 b판사들       0   \n",
       "495  495  ynat-v1_train_00495  o시티·리버=L3·4ea확;…아스널 20년만에D\"스리그Y좌절       1   \n",
       "496  496  ynat-v1_train_00496           조소앙이 쓴 독립운I#1평전 유방z *Ep역       0   \n",
       "497  497  ynat-v1_train_00497      김영란법 때문에E애플 t이폰 초청70못받7 r국 언.       3   \n",
       "499  499  ynat-v1_train_00499                      신:p(피U 로y의 시-       0   \n",
       "\n",
       "     punctuation_count  total_chars                       translated_text  \\\n",
       "0                    3           32   정나 :파1 미사와 함께 KT( 이용기간 에이 단] 큐분종U2보   \n",
       "2                    3           22            중 김정) 자주통일 새,?아르 자형열1나가야1보   \n",
       "3                    0           29         갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩   \n",
       "4                    2           28          피메이대선나앞두고 R2fr단 발] $비해 감시 강화   \n",
       "5                    0           30     아름다운성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다   \n",
       "..                 ...          ...                                   ...   \n",
       "494                  2           25             대형서점엔=없uDtOJ네yC과 손}는 비판사들   \n",
       "495                  3           33  그만큼시티·리버=L3·4개확;…아스널 20년만에디\"스리그그리고좌절   \n",
       "496                  2           24            조소앙이 쓴 독립운나#1평전 유방와 함께 *엡역   \n",
       "497                  1           29   김영란법 때문에그리고애플 티이폰 초청70못받7 아르 자형국 언.   \n",
       "499                  3           13                      신:피(피안에 로그리고의 시-   \n",
       "\n",
       "                                      translated_words foreign_chars  \\\n",
       "0    {'i': '나', ':': ':', '1': '1', 'z': '와 함께', 'K...    (:KQTU]eiz   \n",
       "2     {'m': '중', ')': ')', ',?r': ',?아르 자형', '1': '1'}           )mr   \n",
       "3                     {'8': '8', '27': '27', '…': '…'}             …   \n",
       "4    {'pI美': '피메이', 'I': '나', 'R2fr': 'R2fr', ']': ...      $IR]fpr美   \n",
       "5          {'美': '아름다운', '6': '6', '1': '1', '·': '·'}            ·美   \n",
       "..                                                 ...           ...   \n",
       "494  {'=': '=', 'uDtOJ': 'uDtOJ', 'yC': 'yC', '}': ...    =CDJObtuy}   \n",
       "495  {'o': '그만큼', '·': '·', '=L3·4ea': '=L3·4개', ';...   \";=DLYaeo·…   \n",
       "496           {'I#1': '나#1', 'z': '와 함께', '*Ep': '*엡'}        #*EIpz   \n",
       "497  {'E': '그리고', 't': '티', '70': '70', '7': '7', '...           Ert   \n",
       "499    {':p(': ':피(', 'U': '안에', 'y': '그리고', '-': '-'}        (-:Upy   \n",
       "\n",
       "         detected_languages  \\\n",
       "0             [English, sq]   \n",
       "2             [cy, English]   \n",
       "3                        []   \n",
       "4    [no, English, Chinese]   \n",
       "5             [ko, Chinese]   \n",
       "..                      ...   \n",
       "494           [cy, English]   \n",
       "495           [English, ca]   \n",
       "496           [English, pl]   \n",
       "497           [English, da]   \n",
       "499           [English, tl]   \n",
       "\n",
       "                                 Back_Translation_text  \\\n",
       "0                                  P1 MISAZ KT (U2E 만)   \n",
       "2                                           나는 새인가요? 1   \n",
       "3                    GNU 8 주말에 열리는 27,000...시장은 불법 보조금   \n",
       "4       R2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2F2   \n",
       "5                           결혼한 여성 6명 중 1명은 결코 빚을 잃었다.   \n",
       "..                                                 ...   \n",
       "494                                        판사와 판사가 있다.   \n",
       "495                  oCity-River=L3·4ea확; 20년 안에 아르헨티나   \n",
       "496          The Independent I#1 Peace Breastz 에프 스테이션   \n",
       "497  Eaple Tifon에 대한 Kim 영국의 법률은 70을 7 개의 방사선을 받지 않...   \n",
       "499                                           P (왕의 P)   \n",
       "\n",
       "                                Back_Translation_words  \n",
       "0    {'정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보': 'P1 MISAZ...  \n",
       "2             {'m 김정) 자주통일 새,?r열1나가야1보': '나는 새인가요? 1'}  \n",
       "3    {'갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩': 'GNU 8 주말에 열...  \n",
       "4    {'pI美대선I앞두고 R2fr단 발] $비해 감시 강화': 'R2F2F2F2F2F2...  \n",
       "5    {'美성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다': '결혼한 여성 6명 ...  \n",
       "..                                                 ...  \n",
       "494       {'대형서점엔=없uDtOJ네yC과 손}는 b판사들': '판사와 판사가 있다.'}  \n",
       "495  {'o시티·리버=L3·4ea확;…아스널 20년만에D\"스리그Y좌절': 'oCity-R...  \n",
       "496  {'조소앙이 쓴 독립운I#1평전 유방z *Ep역': 'The Independent ...  \n",
       "497  {'김영란법 때문에E애플 t이폰 초청70못받7 r국 언.': 'Eaple Tifon...  \n",
       "499                      {'신:p(피U 로y의 시-': 'P (왕의 P)'}  \n",
       "\n",
       "[362 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#노이즈가 포함된 데이터 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce_text_noise_df(df, noise_ratio=0.5):\n",
    "    num_samples = len(df)\n",
    "    num_noisy = int(noise_ratio * num_samples)\n",
    "    noisy_indices = random.sample(range(num_samples), num_noisy)\n",
    "    df_noisy = df.copy()\n",
    "    for idx in noisy_indices:\n",
    "        original_text = df_noisy.at[idx, 'text']\n",
    "        noisy_text = add_noise_to_text(original_text)\n",
    "        df_noisy.at[idx, 'text'] = noisy_text\n",
    "    return df_noisy, noisy_indices\n",
    "\n",
    "\n",
    "\n",
    "def add_noise_to_text(text):\n",
    "    # 텍스트에 임의의 노이즈를 추가하는 함수 (예: 단어 순서 섞기, 랜덤 단어 추가, 단어 삭제)\n",
    "    words = text.split()\n",
    "    random.shuffle(words)\n",
    "\n",
    "    # 단어 삭제\n",
    "    num_words_to_delete = random.randint(2, 15)  # 2에서 15개의 단어 삭제\n",
    "    for _ in range(num_words_to_delete):\n",
    "        if words:  # 리스트가 비어있지 않은 경우에만 삭제\n",
    "            delete_position = random.randint(0, len(words) - 1)\n",
    "            del words[delete_position]\n",
    "\n",
    "    # 랜덤 단어 추가\n",
    "    # 랜덤 단어 목록 (한국어)\n",
    "    random_words = ['사과', '바나나', '자동차', '컴퓨터', '학교', '책', '강아지', '고양이', '하늘', '바다', '산', 'सेब', 'केला', 'कार', 'कंप्यूटर', 'स्कूल', 'किताब', 'कुत्ता', 'बिल्ली', 'आकाश', 'समुद्र', 'पहाड़']\n",
    "    num_random_words_to_add = random.randint(5, 20)  # 5에서 20개의 랜덤 단어 추가\n",
    "    for _ in range(num_random_words_to_add):\n",
    "        random_word = random.choice(random_words)\n",
    "        insert_position = random.randint(0, len(words))\n",
    "        words.insert(insert_position, random_word)\n",
    "\n",
    "    noisy_text = ' '.join(words)\n",
    "    return noisy_text\n",
    "\n",
    "\n",
    "# 텍스트 노이즈 적용\n",
    "train_df_noisy, noisy_text_indices = introduce_text_noise_df(train_df, noise_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>Q분종U2보 고양이 आकाश 고양이 स्कूल कंप्यूटर 고양이 बिल्ली ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ynat-v1_train_00001</td>\n",
       "      <td>आकाश 산 책 आकाश 자동차 바다 समुद्र बिल्ली किताब सेब स...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>m 김정) 자주통일 새,?r열1나가야1보</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ynat-v1_train_00003</td>\n",
       "      <td>किताब कंप्यूटर 얼룩 학교 आकाश 바다 책 पहाड़ 학교 고양이 आक...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>pI美대선I앞두고 R2fr단 발] $비해 감시 강화</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>ynat-v1_train_00495</td>\n",
       "      <td>o시티·리버=L3·4ea확;…아스널 20년만에D\"스리그Y좌절</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>ynat-v1_train_00496</td>\n",
       "      <td>강아지 आकाश 책 बिल्ली 컴퓨터 사과 बिल्ली 컴퓨터 केला पहाड़</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>ynat-v1_train_00497</td>\n",
       "      <td>김영란법 때문에E애플 t이폰 초청70못받7 r국 언.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>ynat-v1_train_00498</td>\n",
       "      <td>स्कूल केला पहाड़ कंप्यूटर 고양이 \"0 바다 आकाश 삶의 학교...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>ynat-v1_train_00499</td>\n",
       "      <td>सेब 바나나 पहाड़ 컴퓨터 컴퓨터 बिल्ली 책 स्कूल बिल्ली केला</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                   ID  \\\n",
       "0      0  ynat-v1_train_00000   \n",
       "1      1  ynat-v1_train_00001   \n",
       "2      2  ynat-v1_train_00002   \n",
       "3      3  ynat-v1_train_00003   \n",
       "4      4  ynat-v1_train_00004   \n",
       "..   ...                  ...   \n",
       "495  495  ynat-v1_train_00495   \n",
       "496  496  ynat-v1_train_00496   \n",
       "497  497  ynat-v1_train_00497   \n",
       "498  498  ynat-v1_train_00498   \n",
       "499  499  ynat-v1_train_00499   \n",
       "\n",
       "                                                  text  target  \n",
       "0    Q분종U2보 고양이 आकाश 고양이 स्कूल कंप्यूटर 고양이 बिल्ली ...       4  \n",
       "1    आकाश 산 책 आकाश 자동차 바다 समुद्र बिल्ली किताब सेब स...       3  \n",
       "2                               m 김정) 자주통일 새,?r열1나가야1보       2  \n",
       "3    किताब कंप्यूटर 얼룩 학교 आकाश 바다 책 पहाड़ 학교 고양이 आक...       5  \n",
       "4                         pI美대선I앞두고 R2fr단 발] $비해 감시 강화       6  \n",
       "..                                                 ...     ...  \n",
       "495                  o시티·리버=L3·4ea확;…아스널 20년만에D\"스리그Y좌절       1  \n",
       "496     강아지 आकाश 책 बिल्ली 컴퓨터 사과 बिल्ली 컴퓨터 केला पहाड़       0  \n",
       "497                      김영란법 때문에E애플 t이폰 초청70못받7 r국 언.       3  \n",
       "498  स्कूल केला पहाड़ कंप्यूटर 고양이 \"0 바다 आकाश 삶의 학교...       0  \n",
       "499   सेब 바나나 पहाड़ 컴퓨터 컴퓨터 बिल्ली 책 स्कूल बिल्ली केला       0  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 다시 Dataset으로 변환\n",
    "train_dataset_noisy = Dataset.from_pandas(train_df_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['idx', 'ID', 'text', 'target'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee42b48ab7c452797268aeec74805f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 토크나이저를 사용하여 데이터 전처리\n",
    "def preprocess_function(examples):\n",
    "    tokenized_inputs = tokenizer(examples['text'], padding=True, truncation=True)\n",
    "    tokenized_inputs['label'] = examples['target']  # 'target'을 'label'로 매핑\n",
    "    tokenized_inputs['idx'] = examples['idx']  # 'idx' 유지\n",
    "    return tokenized_inputs\n",
    "\n",
    "train_dataset_noisy = train_dataset_noisy.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=['text', 'ID', 'target']  # 'text', 'ID', 'target' 컬럼 제거\n",
    ")\n",
    "\n",
    "# 데이터 콜레이터 설정 (동적 패딩)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=BertTokenizerFast(name_or_path='klue/bert-base', vocab_size=32000, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}, padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f1_metric\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mpredictions, references\u001b[38;5;241m=\u001b[39mlabels, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 훈련 인자 설정\u001b[39;00m\n\u001b[1;32m     11\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m---> 12\u001b[0m             output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mmodel_path,\n\u001b[1;32m     13\u001b[0m             overwrite_output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m             do_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m             do_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m             do_predict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m             logging_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m             eval_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m             save_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m             logging_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     21\u001b[0m             \u001b[38;5;66;03m# eval_steps=100,\u001b[39;00m\n\u001b[1;32m     22\u001b[0m             \u001b[38;5;66;03m# save_steps=100,\u001b[39;00m\n\u001b[1;32m     23\u001b[0m             save_total_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     24\u001b[0m             learning_rate\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2e-05\u001b[39m, \u001b[38;5;66;03m# 가능\u001b[39;00m\n\u001b[1;32m     25\u001b[0m             adam_beta1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;66;03m# 불가\u001b[39;00m\n\u001b[1;32m     26\u001b[0m             adam_beta2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.999\u001b[39m, \u001b[38;5;66;03m# 불가\u001b[39;00m\n\u001b[1;32m     27\u001b[0m             adam_epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-08\u001b[39m, \u001b[38;5;66;03m# 불가\u001b[39;00m\n\u001b[1;32m     28\u001b[0m             weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;66;03m# 불가\u001b[39;00m\n\u001b[1;32m     29\u001b[0m             lr_scheduler_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# 불가\u001b[39;00m\n\u001b[1;32m     30\u001b[0m             per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, \u001b[38;5;66;03m# 가능\u001b[39;00m\n\u001b[1;32m     31\u001b[0m             per_device_eval_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, \u001b[38;5;66;03m# 32인 건 이유가 있다.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m             num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;66;03m# 불가\u001b[39;00m\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;66;03m# load_best_model_at_end=True,\u001b[39;00m\n\u001b[1;32m     34\u001b[0m             metric_for_best_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_f1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     35\u001b[0m             greater_is_better\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     36\u001b[0m             seed\u001b[38;5;241m=\u001b[39mSEED, \u001b[38;5;66;03m# 불가? 가급적 건드리지 말기\u001b[39;00m\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 모델 초기화\u001b[39;00m\n\u001b[1;32m     41\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "# 평가 메트릭 정의 (F1 스코어)\n",
    "f1_metric = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return f1_metric.compute(predictions=predictions, references=labels, average='macro')\n",
    "\n",
    "\n",
    "# 훈련 인자 설정\n",
    "training_args = TrainingArguments(\n",
    "            output_dir=self.model_path,\n",
    "            overwrite_output_dir=True,\n",
    "            do_train=True,\n",
    "            do_eval=True,\n",
    "            do_predict=True,\n",
    "            logging_strategy='epoch',\n",
    "            eval_strategy='epoch',\n",
    "            save_strategy='epoch',\n",
    "            logging_steps=100,\n",
    "            # eval_steps=100,\n",
    "            # save_steps=100,\n",
    "            save_total_limit=1,\n",
    "            learning_rate= 2e-05, # 가능\n",
    "            adam_beta1 = 0.9, # 불가\n",
    "            adam_beta2 = 0.999, # 불가\n",
    "            adam_epsilon=1e-08, # 불가\n",
    "            weight_decay=0.01, # 불가\n",
    "            lr_scheduler_type='linear', # 불가\n",
    "            per_device_train_batch_size=32, # 가능\n",
    "            per_device_eval_batch_size=32, # 32인 건 이유가 있다.\n",
    "            num_train_epochs=2, # 불가\n",
    "            # load_best_model_at_end=True,\n",
    "            metric_for_best_model='eval_f1',\n",
    "            greater_is_better=True,\n",
    "            seed=SEED, # 불가? 가급적 건드리지 말기\n",
    ")\n",
    "\n",
    "\n",
    "# 모델 초기화\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(DEVICE)\n",
    "\n",
    "# Trainer 설정 및 학습\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_noisy,\n",
    "    #eval_dataset=valid_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# 학습 완료 후 성능 평가\n",
    "print(\"\\n모델 1 성능 평가:\")\n",
    "eval_results = trainer.evaluate(eval_dataset=valid_dataset)\n",
    "print(f\"F1 Score: {eval_results['eval_f1']:.4f}\")\n",
    "\n",
    "# 성능 저장\n",
    "model1_f1 = eval_results['eval_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
